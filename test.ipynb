{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.sgd import SGD\n",
    "\n",
    "\n",
    "class MetaSGD(SGD):\n",
    "    def __init__(self, net, *args, **kwargs):\n",
    "        super(MetaSGD, self).__init__(*args, **kwargs)\n",
    "        self.net = net\n",
    "\n",
    "    def set_parameter(self, current_module, name, parameters):\n",
    "        if '.' in name:\n",
    "            name_split = name.split('.')\n",
    "            module_name = name_split[0]\n",
    "            rest_name = '.'.join(name_split[1:])\n",
    "            for children_name, children in current_module.named_children():\n",
    "                if module_name == children_name:\n",
    "                    self.set_parameter(children, rest_name, parameters)\n",
    "                    break\n",
    "        else:\n",
    "            current_module._parameters[name] = parameters\n",
    "\n",
    "    def meta_step(self, grads):\n",
    "        group = self.param_groups[0]\n",
    "        weight_decay = group['weight_decay']\n",
    "        momentum = group['momentum']\n",
    "        dampening = group['dampening']\n",
    "        nesterov = group['nesterov']\n",
    "        lr = group['lr']\n",
    "\n",
    "        # 根据weight_decay、momentum、nesterov对梯度进行更新\n",
    "        for (name, parameter), grad in zip(self.net.named_parameters(), grads):\n",
    "            parameter.detach_()\n",
    "            if weight_decay != 0:\n",
    "                grad_wd = grad.add(parameter, alpha=weight_decay)\n",
    "            else:\n",
    "                grad_wd = grad\n",
    "            if momentum != 0 and 'momentum_buffer' in self.state[parameter]:\n",
    "                buffer = self.state[parameter]['momentum_buffer']\n",
    "                grad_b = buffer.mul(momentum).add(grad_wd, alpha=1-dampening)\n",
    "            else:\n",
    "                grad_b = grad_wd\n",
    "            if nesterov:\n",
    "                grad_n = grad_wd.add(grad_b, alpha=momentum)\n",
    "            else:\n",
    "                grad_n = grad_b\n",
    "            self.set_parameter(self.net, name, parameter.add(grad_n, alpha=-lr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0.],\n",
       "         [0., 0., 1., 0.]]),\n",
       " tensor([[0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0.]]),\n",
       " tensor([[0],\n",
       "         [2]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "logits = torch.randn((2,4))\n",
    "target = torch.tensor([0,2])\n",
    "torch.zeros_like(logits).scatter_(1, target.unsqueeze(1), 1), torch.zeros_like(logits), target.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2],\n",
      "        [2]]) tensor([[1., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[2., 0., 0., 0.],\n",
       "         [0., 0., 2., 0.]]),\n",
       " tensor([[-1.9150, -0.0000, -0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -2.5433, -0.0000]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = torch.randn((2,4))\n",
    "target = torch.tensor([0,2])\n",
    "delta = torch.tensor([[2],[2]])\n",
    "y_t = logits\n",
    "y_t_target = y_t * torch.zeros_like(y_t).scatter_(1, target.unsqueeze(1), 1)\n",
    "y_t_delta = delta * torch.zeros_like(y_t).scatter_(1, target.unsqueeze(1), 1)\n",
    "y_t = y_t_target - y_t_delta\n",
    "y_t_delta, y_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "m1 = torch.nn.Linear(1, 1)\n",
    "m2 = torch.nn.Linear(1, 2)\n",
    "m3 = torch.nn.Linear(1, 3)\n",
    "trainable_list1 = torch.nn.ModuleList([m1, m2, m3])\n",
    "trainable_list2 = torch.nn.ModuleList([m1, m2, m3])\n",
    "\n",
    "optimizer1 = optim.SGD(trainable_list1.parameters(),\n",
    "                       lr=0.05,\n",
    "                       momentum=0.9,\n",
    "                       weight_decay=5e-4)\n",
    "optimizer2 = optim.SGD(trainable_list2[1:-1].parameters(),\n",
    "                       lr=0.05,\n",
    "                       momentum=0.9,\n",
    "                       weight_decay=5e-4)\n",
    "\n",
    "# 加载 optimizer1 的状态字典\n",
    "state_dict_optimizer1 = optimizer1.state_dict()\n",
    "\n",
    "# 获取 optimizer2 的状态字典\n",
    "state_dict_optimizer2 = optimizer2.state_dict()\n",
    "\n",
    "# 通过模型的名称匹配参数组，只保留 optimizer1 中与 optimizer2 相同模型的参数的部分\n",
    "for param_group1 in state_dict_optimizer1['param_groups']:\n",
    "    param_names1 = set(param_group1['params'])\n",
    "    print(param_names1)\n",
    "    matched_params1 = {k: v for k, v in state_dict_optimizer1['state'].items() if k in param_names1}\n",
    "    \n",
    "    # 找到 optimizer2 中相同模型的参数组\n",
    "    param_group2 = next((param_group2 for param_group2 in state_dict_optimizer2['param_groups'] if set(param_group2['params']) == param_names1), None)\n",
    "    \n",
    "    # 如果找到匹配的参数组，则更新它\n",
    "    if param_group2 is not None:\n",
    "        param_group2['params'] = list(matched_params1.values())\n",
    "\n",
    "# 将更新后的状态字典加载到 optimizer2\n",
    "optimizer2.load_state_dict(state_dict_optimizer2)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "KD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
